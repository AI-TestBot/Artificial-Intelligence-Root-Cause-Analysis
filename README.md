# Artificial-Intelligence-Root-Cause-Analysis

## Review

**A Survey on Failure Analysis and Fault Injection in AI Systems.**<br>
*G Yu, G Tan, H Huang, Z Zhang, P Chen, R Natella, Z Zheng.*<br>
ArXiv, 2024.
[[Paper](https://arxiv.org/pdf/2407.00125)]

## White Box Testing

**LUNA: A Model-Based Universal Analysis Framework for Large Language Models.**<br>
*D Song, X **e, J Song, D Zhu, Y Huang, F Juefei-Xu, L Ma.*<br>
IEEE Transactions on Software Engineering, 2024.
[[Paper](https://arxiv.org/pdf/2310.14211)]
[[Homepage](https://sites.google.com/view/llm-luna)]

## Explainability

**Explainability for large language models: A survey.**<br>
*H Zhao, H Chen, F Yang, N Liu, H Deng, H Cai, S Wang, D Yin, M Du.*<br>
ACM Transactions on Intelligent Systems and Technology, 2024.
[[Paper](https://dl.acm.org/doi/pdf/10.1145/3639372)]

**Rethinking interpretability in the era of large language models.**<br>
*C Singh, JP Inala, M Galley, R Caruana, J Gao.*<br>
arxiv:2402.01761, 2024.
[[Paper](https://arxiv.org/pdf/2402.01761)]

**IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons.**<br>
*D Shi, R **, T Shen, W Dong, X Wu, D **ong.*<br>
arxiv:2406.18406, 2024.
[[Paper](https://arxiv.org/pdf/2406.18406)]

**Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons.**<br>
*Y Leng, D **ong.*<br>
arxiv:2407.06488, 2024.
[[Paper](https://arxiv.org/pdf/2407.06488)]

**Mitigating Privacy Seesaw in Large Language Models: Augmented Privacy Neuron Editing via Activation Patching.**<br>
*X Wu, W Dong, S Xu, D **ong.*<br>
Findings of the Association for Computational Linguistics ACL 2024, 2024.
[[Paper](https://aclanthology.org/2024.findings-acl.315.pdf)]
